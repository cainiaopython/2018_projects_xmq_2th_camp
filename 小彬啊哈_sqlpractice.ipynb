{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#        将dataframe导入数据库\n",
    "\n",
    "\n",
    "## 步骤\n",
    "* json格式数据导入，python和java两表合并，去重\n",
    "* 清洗时间、薪水\n",
    "* 连接数据库\n",
    "* 依次导入城市，公司和职位表\n",
    "* 关闭连接"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pymysql\n",
    "import json\n",
    "import re\n",
    "from pandas import DataFrame,Series\n",
    "\n",
    "#读取josn格式文件\n",
    "with open('C:\\\\Users\\\\jinbin\\\\Desktop\\\\job_全国_python_2018_03_29.json','r') as f:\n",
    "    temp=json.loads(f.read())    \n",
    "data1=DataFrame(temp)             #导入df\n",
    "with open('C:\\\\Users\\\\jinbin\\\\Desktop\\\\job_全国_java_2018_03_29.json','r') as f:\n",
    "    temp=json.loads(f.read())\n",
    "data2=DataFrame(temp)\n",
    "\n",
    "\n",
    "data1=data1.drop_duplicates()     #先去重后再合并\n",
    "data2=data2.drop_duplicates()   \n",
    "data=pd.concat([data1,data2],ignore_index=True)#合并java和python的数据\n",
    "    \n",
    "\n",
    "\n",
    "#清洗时间\n",
    "time=[]                          \n",
    "pat1='[_ ]|-'\n",
    "for i in range(len(data['create_time'])):\n",
    "    da=re.split(pat1,data['create_time'][i])\n",
    "    str1=da[0] + \"-\" + da[1] + \"-\" + da[2]\n",
    "    time.append(str1)\n",
    "#去除原时间数据，并加入新的时间数据\n",
    "data=data.drop('create_time',axis=1)\n",
    "data=pd.merge(data,DataFrame(time,columns=['create_time']),right_index=True,left_index=True)\n",
    "\n",
    "\n",
    "#清洗薪水\n",
    "pat2=r'([kK]-)|[kK]'\n",
    "smin=[]\n",
    "smax=[]\n",
    "for i in range(len(data['salary'])):\n",
    "    str2=re.split(pat2,data['salary'][i])\n",
    "    smin.append(str2[0])\n",
    "    smax.append(str2[2])\n",
    "#对有异常的最大薪水进行处理\n",
    "for i in range(len(smax)):\n",
    "    if (smax[i]=='以上'):\n",
    "        smax[i]=smin[i]\n",
    "#去除原薪水数据，并加入新的薪水数据\n",
    "salary=DataFrame({'min_salary':smin,'max_salary':smax},columns=['min_salary','max_salary'])\n",
    "data=data.drop('salary',axis=1)\n",
    "data=pd.merge(data,salary,right_index=True,left_index=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#写入城市表\n",
    "city_name = data['city'].value_counts().index #过滤掉重复的城市\n",
    "city_id = np.arange(len(city_name)) + 1001    #赋予城市编号\n",
    "city_dict = dict(zip(city_name,city_id))         #城市与编号对应的键值对\n",
    "#连接数据库\n",
    "conn = pymysql.connect(host = 'localhost',port = 3306,user = 'root',\n",
    "                       passwd = 'apples',db = 'python', charset = \"utf8\")\n",
    "cursor = conn.cursor()                   #创建游标对象\n",
    "for i in range(len(city_name)):\n",
    "    sql = \"insert into city value\" + str(tuple([city_id[i],city_name[i]]))\n",
    "    cursor.execute(sql)\n",
    "    conn.commit()\n",
    "    \n",
    "#写入公司表\n",
    "cond = data.duplicated(['company_full_names'])   #得到公司名的出现重复时的位置   为True时表示此位置的值重复了\n",
    "comp_full_name = data[-cond]['company_full_names']        #过滤掉重复的公司\n",
    "comp_name = data[-cond]['company_name']                   #公司别名\n",
    "comp_id = np.arange(len(comp_full_name)) + 2001                     #赋予公司编号\n",
    "comp_dict = dict(zip(comp_full_name,comp_id))             #公司与编号对应的键值对\n",
    "#循环sql语句导入数据\n",
    "for i in range(len(comp_full_name)):\n",
    "    sql = \"insert into comp(comp_id,comp_full_name,comp_name) value\" + str(tuple([comp_id[i],comp_full_name.iloc[i],comp_name.iloc[i]]))\n",
    "    cursor.execute(sql)\n",
    "    conn.commit()\n",
    "    \n",
    "#写入职位表\n",
    "#有replace函数结合之间的城市编号  公司编号的键值对，替换成城市和公司的编号\n",
    "DATA=pd.concat([data.drop('city',axis=1),data['city'].replace(city_dict)],axis=1)\n",
    "DATA=pd.concat([DATA.drop('company_full_names',axis=1),\n",
    "                DATA['company_full_names'].replace(comp_dict)],axis=1)\n",
    "\n",
    "for i in range(len(DATA)):\n",
    "    sql = '''insert into postn(postn_id,postn_name,postn_salary_max,postn_salary_min,postn_create_time,comp_id,city_id) value''' + str(tuple([DATA['positionId'][i],DATA['positionName'][i],DATA['max_salary'][i],DATA['min_salary'][i],DATA['create_time'][i],DATA['company_full_names'][i],DATA['city'][i]]))\n",
    "    cursor.execute(sql)\n",
    "    conn.commit()\n",
    "    \n",
    "cursor.close()    #关闭游标\n",
    "conn.close()      #关闭连接"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
